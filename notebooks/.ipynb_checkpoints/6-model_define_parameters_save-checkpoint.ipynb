{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n神经网络的定义方式，获取参数，保存参数\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "神经网络的定义方式，获取参数，保存参数\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run read_fashion_image.ipynb\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([x.reshape(28,28) for x in x_train ])\n",
    "x_test = np.array([x.reshape(28,28) for x in x_test ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方式1：一次性定义全部网络结构\n",
    "model = tf.keras.models.Sequential([\n",
    "                                    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                                    tf.keras.layers.Dense(256, activation='relu',),\n",
    "                                    tf.keras.layers.Dense(10, activation='softmax')\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MLP"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方式2：以序列方式定义，分别定义每一层\n",
    "class MLP(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        flatten_layer = tf.keras.layers.Flatten()\n",
    "        def dense_layer(name=None):\n",
    "            if not name:\n",
    "                return tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
    "            else:\n",
    "                return tf.keras.layers.Dense(256, activation=tf.nn.relu, name=name)\n",
    "        dropout_layer = tf.keras.layers.Dropout(0.5)\n",
    "        output_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "        self.model = tf.keras.models.Sequential()\n",
    "        self.model.add(flatten_layer)\n",
    "        for i in range(2):\n",
    "#             self.model.add(dense_layer(\"dense%d\" % i)) # 每一层起不同的名字\n",
    "            self.model.add(dense_layer()) # 每一层起不同的名字\n",
    "            self.model.add(dropout_layer)\n",
    "        self.model.add(output_layer)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)\n",
    "    \n",
    "model = MLP()\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MLP"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方式3：以类的方式定义，更工程化\n",
    "class MLP(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten_layer = tf.keras.layers.Flatten()\n",
    "        self.dense_layer1 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
    "        self.dense_layer2 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
    "        self.dropout_layer = tf.keras.layers.Dropout(0.5)\n",
    "        self.output_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.flatten_layer(inputs)\n",
    "        x = self.dense_layer1(x)\n",
    "        x = self.dense_layer2(x) \n",
    "        # 如果只写成dense_layer，并调用两次 x = dense_layer(x) 会报错\n",
    "        # 因为第一次执行这句后，dense_layer会变成一个神经网络层，输入是784维，所以再次调用时，输入维度不正确，就会报错\n",
    "        output = self.output_layer(x)     \n",
    "        return output\n",
    "    \n",
    "model = MLP()\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.5),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.8251 - accuracy: 0.6935 - val_loss: 0.5518 - val_accuracy: 0.7838\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.5461 - accuracy: 0.7980 - val_loss: 0.4970 - val_accuracy: 0.8184\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4701 - accuracy: 0.8261 - val_loss: 0.4989 - val_accuracy: 0.8086\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4394 - accuracy: 0.8376 - val_loss: 0.5237 - val_accuracy: 0.8095\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4186 - accuracy: 0.8466 - val_loss: 0.4105 - val_accuracy: 0.8482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3aaeb668>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=5,\n",
    "          batch_size=256,\n",
    "          validation_data=(x_test, y_test),\n",
    "          validation_freq=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取每一层的权重系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'mlp_6/sequential_1/dense_14/kernel:0' shape=(784, 256) dtype=float32, numpy=\n",
       "array([[ 0.00294566,  0.05004987,  0.00271001, ...,  0.03959084,\n",
       "        -0.05993354, -0.06199143],\n",
       "       [ 0.05427834,  0.06871633,  0.06340374, ..., -0.05930483,\n",
       "         0.04408232, -0.02000068],\n",
       "       [-0.06381077,  0.0587069 , -0.01078447, ..., -0.0060904 ,\n",
       "        -0.01464957, -0.02623158],\n",
       "       ...,\n",
       "       [ 0.02187521, -0.03366455,  0.0260867 , ...,  0.05555315,\n",
       "         0.03741949,  0.01170047],\n",
       "       [-0.00589255,  0.0134085 , -0.01863818, ..., -0.04816734,\n",
       "        -0.0276657 ,  0.02965577],\n",
       "       [-0.02482702,  0.03131078,  0.03506022, ..., -0.05677408,\n",
       "        -0.07807521,  0.00352092]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'mlp_6/sequential_1/dense_14/bias:0' shape=(256,) dtype=float32, numpy=\n",
       "array([ 0.11102301,  0.04962588,  0.10887065, -0.05661264,  0.0093953 ,\n",
       "        0.00237108,  0.07363104,  0.01493046, -0.02420369, -0.13762571,\n",
       "        0.03165716,  0.02491756, -0.03754677, -0.02195394,  0.09384637,\n",
       "        0.17899649,  0.09422062, -0.13498096,  0.05634186, -0.02349562,\n",
       "        0.16778252,  0.14011617,  0.07608903,  0.06117399, -0.13008495,\n",
       "       -0.02320166, -0.01270711,  0.39943975, -0.01971927,  0.05362552,\n",
       "        0.20469756,  0.04425382, -0.33079726,  0.00875897,  0.05691639,\n",
       "        0.07537393,  0.22522433,  0.13301359,  0.0330934 ,  0.16991006,\n",
       "       -0.01340355, -0.01575116,  0.10794733, -0.02128834,  0.11518096,\n",
       "        0.12628207, -0.01013546, -0.09367588,  0.08754671, -0.03214873,\n",
       "        0.10295682,  0.06585162, -0.0263508 , -0.08750086,  0.11789899,\n",
       "        0.15809304,  0.08076334, -0.01024261,  0.2851429 ,  0.04711298,\n",
       "       -0.01060936,  0.18932113,  0.03836387,  0.12258097, -0.03378522,\n",
       "        0.19089353,  0.14089578,  0.0274729 ,  0.08020557,  0.18196663,\n",
       "        0.0829467 ,  0.05848112, -0.00251874, -0.01655179, -0.10678762,\n",
       "        0.00890217, -0.03965533,  0.00437818, -0.05661002,  0.20441379,\n",
       "        0.12186044,  0.05712357,  0.06479861, -0.08531025,  0.1268208 ,\n",
       "       -0.00187048,  0.13437551, -0.00744984, -0.19280174,  0.09220546,\n",
       "        0.17382032,  0.1345004 ,  0.0618853 ,  0.08585069,  0.15835635,\n",
       "        0.03219577,  0.00526263,  0.02800308, -0.00244229,  0.03906883,\n",
       "       -0.01046774, -0.1278579 , -0.08660085, -0.21205693, -0.00111992,\n",
       "        0.02445809, -0.02553142,  0.0212695 , -0.01596507,  0.08494157,\n",
       "        0.02060331,  0.14412785, -0.01751304,  0.24107285,  0.1834582 ,\n",
       "        0.03978686, -0.01225123,  0.23013227, -0.15079458, -0.01548273,\n",
       "       -0.0407339 ,  0.170146  , -0.05582927,  0.10414678,  0.18132065,\n",
       "       -0.00393029,  0.10388459,  0.13456629,  0.14434293,  0.02775923,\n",
       "       -0.02607872, -0.02111527, -0.00708058, -0.10636743, -0.03305907,\n",
       "       -0.15644668,  0.17955913,  0.06160042, -0.04387603,  0.06357399,\n",
       "       -0.23871145, -0.01707208, -0.00411739,  0.0833182 , -0.01455101,\n",
       "       -0.20039605, -0.0166847 ,  0.24919601, -0.03915235, -0.01579886,\n",
       "        0.06440786,  0.18685612,  0.00354419,  0.00163492,  0.00629674,\n",
       "       -0.0056866 ,  0.12867446, -0.15218517, -0.01695853,  0.3180189 ,\n",
       "       -0.153214  ,  0.29402184,  0.12635723,  0.0878507 ,  0.1243161 ,\n",
       "       -0.02102108,  0.15190184, -0.02208932,  0.18217717,  0.04598266,\n",
       "        0.23576425,  0.07101566,  0.00284138, -0.02273031,  0.09861934,\n",
       "        0.04609499, -0.00712197, -0.00209398, -0.06608087,  0.1327116 ,\n",
       "       -0.15351081, -0.24757372, -0.00178967,  0.12390503, -0.02454395,\n",
       "        0.02074   ,  0.00760131,  0.2142634 ,  0.1570776 ,  0.08139477,\n",
       "        0.14209111,  0.26830935,  0.00109764,  0.19699022,  0.17062299,\n",
       "        0.26039615,  0.07960381,  0.03008112,  0.12405901, -0.05995683,\n",
       "       -0.0945922 ,  0.15645841,  0.03583162, -0.01954888, -0.04910975,\n",
       "        0.12098379,  0.3147096 ,  0.01069004,  0.11722665, -0.14311324,\n",
       "       -0.10592047,  0.03978347, -0.08622465,  0.00600429, -0.1283971 ,\n",
       "        0.13757634,  0.11396366,  0.12145387,  0.07367475, -0.01121978,\n",
       "        0.16044787, -0.04417892,  0.05471395, -0.02055804,  0.0436822 ,\n",
       "       -0.02381612,  0.13920164, -0.02380719,  0.07882682, -0.01786464,\n",
       "       -0.22496337,  0.00282663, -0.00729347,  0.03723671,  0.07861111,\n",
       "        0.19799323, -0.16608056,  0.08928446,  0.22329026, -0.11997532,\n",
       "        0.12383011,  0.00604413,  0.02630352,  0.11435847, -0.01640587,\n",
       "        0.11797036,  0.17772359,  0.28507766,  0.02154517, -0.01976963,\n",
       "        0.11399044, -0.02216761,  0.08554234,  0.00511655, -0.23252042,\n",
       "        0.16153729], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save numpy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.ones((2,2))\n",
    "print(tensor)\n",
    "np.save(\"test.npy\", tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load \n",
    "tensor = np.load(\"test.npy\")\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.8569112e-05, 6.1693376e-05, 2.7899505e-05, 7.8957237e-05,\n",
       "        3.2714339e-05, 1.8832438e-01, 2.9896195e-05, 2.3371458e-01,\n",
       "        1.2878830e-03, 5.7635337e-01],\n",
       "       [1.4052604e-03, 1.6857641e-05, 9.5151764e-01, 7.2085073e-05,\n",
       "        4.1229506e-03, 2.7934652e-07, 4.2829890e-02, 7.5904501e-07,\n",
       "        3.2777960e-05, 1.4482712e-06],\n",
       "       [2.3909356e-08, 1.0000000e+00, 4.0523943e-10, 3.5288792e-08,\n",
       "        1.8345388e-10, 2.0642683e-14, 3.3352640e-11, 3.1342438e-14,\n",
       "        9.0871261e-13, 2.2048415e-14],\n",
       "       [2.3080089e-08, 9.9999976e-01, 7.7677798e-10, 2.7649963e-07,\n",
       "        7.8283746e-10, 1.7237976e-13, 1.2632465e-10, 3.3389960e-13,\n",
       "        3.4676006e-12, 2.6574381e-13],\n",
       "       [2.6186955e-01, 1.6260222e-03, 1.5092772e-01, 2.5567267e-02,\n",
       "        1.6019188e-02, 1.0647790e-03, 5.2746540e-01, 6.6100073e-04,\n",
       "        1.4291835e-02, 5.0711236e-04]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer mlp_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "model(x_train[:5])\n",
    "model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.8569112e-05, 6.1693376e-05, 2.7899505e-05, 7.8957237e-05,\n",
       "        3.2714339e-05, 1.8832438e-01, 2.9896195e-05, 2.3371458e-01,\n",
       "        1.2878830e-03, 5.7635337e-01],\n",
       "       [1.4052604e-03, 1.6857641e-05, 9.5151764e-01, 7.2085073e-05,\n",
       "        4.1229506e-03, 2.7934652e-07, 4.2829890e-02, 7.5904501e-07,\n",
       "        3.2777960e-05, 1.4482712e-06],\n",
       "       [2.3909356e-08, 1.0000000e+00, 4.0523943e-10, 3.5288792e-08,\n",
       "        1.8345388e-10, 2.0642683e-14, 3.3352640e-11, 3.1342438e-14,\n",
       "        9.0871261e-13, 2.2048415e-14],\n",
       "       [2.3080089e-08, 9.9999976e-01, 7.7677798e-10, 2.7649963e-07,\n",
       "        7.8283746e-10, 1.7237976e-13, 1.2632465e-10, 3.3389960e-13,\n",
       "        3.4676006e-12, 2.6574381e-13],\n",
       "       [2.6186955e-01, 1.6260222e-03, 1.5092772e-01, 2.5567267e-02,\n",
       "        1.6019188e-02, 1.0647790e-03, 5.2746540e-01, 6.6100073e-04,\n",
       "        1.4291835e-02, 5.0711236e-04]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "问题：搞清楚单层全连接神经网络的权重系数有多少，矩阵结构是怎样的。\n",
    "  比如：同一层里的多个神经元，bias有多少个，每个神经元都不同还是共享的？明显是不共享的。\n",
    "  \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
