{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n另一种神经网络的定义方式，更加灵活\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "另一种神经网络的定义方式，更加灵活\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run read_fashion_image.ipynb\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([x.reshape(28,28) for x in x_train ])\n",
    "x_test = np.array([x.reshape(28,28) for x in x_test ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方式1：一次性定义全部网络结构\n",
    "# model = tf.keras.models.Sequential([\n",
    "#                                     tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#                                     tf.keras.layers.Dense(256, activation='relu',),\n",
    "#                                     tf.keras.layers.Dense(10, activation='softmax')\n",
    "#                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方式2：分别定义每一层，然后拼接起来\n",
    "flatten_layer = tf.keras.layers.Flatten()\n",
    "dense_layer = tf.keras.layers.Dense(256,activation=tf.nn.relu)\n",
    "dropout_layer = tf.keras.layers.Dropout(0.5)\n",
    "output_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(flatten_layer)\n",
    "for i in range(3):  # 定义多层\n",
    "    model.add(dense_layer) \n",
    "#     model.add(dropout_layer)\n",
    "model.add(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.5),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.7920 - accuracy: 0.7121 - val_loss: 0.5971 - val_accuracy: 0.7891\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.4790 - accuracy: 0.8235 - val_loss: 0.5641 - val_accuracy: 0.7755\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.4202 - accuracy: 0.8439 - val_loss: 0.5993 - val_accuracy: 0.7819\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3863 - accuracy: 0.8569 - val_loss: 0.4588 - val_accuracy: 0.8365\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3599 - accuracy: 0.8670 - val_loss: 0.5282 - val_accuracy: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb2c0bffd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=5,\n",
    "          batch_size=256,\n",
    "          validation_data=(x_test, y_test),\n",
    "          validation_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取每一层的权重系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_2/dense_4/kernel:0' shape=(784, 256) dtype=float32, numpy=\n",
       "array([[-0.01326577,  0.05353743, -0.04613684, ...,  0.01512438,\n",
       "        -0.05713975,  0.01790981],\n",
       "       [-0.07171859,  0.06371883, -0.01333776, ..., -0.03662582,\n",
       "        -0.02242934, -0.01900315],\n",
       "       [ 0.01364677, -0.06831619,  0.05898945, ...,  0.07483419,\n",
       "        -0.05738248,  0.05306685],\n",
       "       ...,\n",
       "       [ 0.09154403, -0.00042456,  0.01787029, ...,  0.0581831 ,\n",
       "        -0.05831866, -0.04562314],\n",
       "       [-0.02809519,  0.01002197,  0.0615252 , ...,  0.00797478,\n",
       "         0.04221744, -0.06172889],\n",
       "       [ 0.06210614, -0.01971073, -0.05416953, ...,  0.00129098,\n",
       "        -0.01843722,  0.02099417]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_2/dense_4/bias:0' shape=(256,) dtype=float32, numpy=\n",
       "array([ 2.25194424e-01,  9.12200361e-02, -1.79271977e-02,  9.82341263e-03,\n",
       "        1.96356207e-01,  7.10925041e-03, -1.94994006e-02,  2.36009568e-01,\n",
       "       -1.71681680e-02,  2.13983998e-01,  3.89741594e-03,  6.11486137e-02,\n",
       "        1.12819761e-01,  2.64252275e-02,  2.33323306e-01, -2.25002952e-02,\n",
       "       -8.89730547e-03, -2.24080291e-02,  6.85313046e-02, -4.29421626e-02,\n",
       "        4.05995280e-01,  1.68659136e-01,  1.71183929e-01,  2.29118094e-02,\n",
       "       -1.44290077e-02,  1.05158076e-01, -7.06093619e-03,  2.82583296e-01,\n",
       "       -6.91402704e-03, -4.64737527e-02,  1.12297870e-02,  4.96082800e-03,\n",
       "        4.50371087e-01, -3.88799906e-02, -4.65038158e-02,  2.53632933e-01,\n",
       "       -1.33890575e-02, -2.40896512e-02, -2.76312903e-02,  1.07261933e-01,\n",
       "        2.51288533e-01, -4.90944320e-03, -1.61959156e-02,  3.54464911e-02,\n",
       "        1.88793436e-01,  7.96761215e-02, -2.56161422e-01, -1.43016595e-02,\n",
       "       -3.48973796e-02,  4.32712995e-02, -2.22906470e-02, -1.45082613e-02,\n",
       "       -2.72566900e-02, -1.09202713e-02, -3.01934648e-02, -1.12844026e-02,\n",
       "        1.22090150e-02, -2.33730264e-02,  9.98360664e-03,  6.11585788e-02,\n",
       "       -1.94781143e-02,  4.05986374e-03,  3.95410746e-01, -1.73838437e-02,\n",
       "        1.74405977e-01, -1.31256776e-02,  3.39876860e-01, -1.22905970e-02,\n",
       "        1.38525143e-02,  1.90588890e-03,  1.31787136e-01, -4.36469633e-03,\n",
       "        1.53698949e-02,  5.96833276e-03, -2.08930820e-02,  1.84201986e-01,\n",
       "       -2.13751160e-02,  6.70217797e-02,  2.31154844e-01,  2.20520139e-01,\n",
       "        1.21322973e-03, -1.17083900e-02,  1.52744025e-01,  9.38463509e-02,\n",
       "       -4.19876538e-02, -1.00244008e-01,  2.59652250e-02,  5.19118786e-01,\n",
       "       -7.14330655e-03, -2.27237586e-02,  1.65258542e-01,  2.40401290e-02,\n",
       "       -5.29512344e-03,  1.81877837e-01,  3.09309632e-01,  9.68602672e-02,\n",
       "       -1.00728767e-02, -3.40952389e-02,  5.92481159e-02,  5.02844527e-02,\n",
       "       -2.99409088e-02,  2.18042791e-01, -5.31499973e-03, -2.21940055e-01,\n",
       "       -2.65557785e-02,  4.83027566e-03, -3.00084781e-02, -1.16751269e-02,\n",
       "        1.88618109e-01,  2.38951236e-01,  6.15402237e-02, -5.94414910e-03,\n",
       "       -9.25751962e-03,  5.86659797e-02,  2.23023161e-01, -1.96759403e-02,\n",
       "        8.06350783e-02,  1.17213614e-02,  1.26766674e-02, -2.07894258e-02,\n",
       "       -7.16162995e-02, -1.51844518e-02,  1.12864792e-01, -2.15299204e-02,\n",
       "       -1.02622278e-01, -3.20342816e-02, -1.26571748e-02,  8.69856775e-02,\n",
       "        9.89988744e-02,  5.78495627e-03,  1.40293136e-01, -4.65223519e-03,\n",
       "        2.93079346e-01,  4.33039293e-03,  8.94492567e-02,  5.06319851e-03,\n",
       "        2.33348727e-01,  3.57849181e-01, -3.28553841e-03, -3.77778448e-02,\n",
       "       -1.25161689e-02,  2.90380325e-03, -3.63685042e-02, -2.14001779e-02,\n",
       "       -1.97758880e-02, -6.11944310e-02, -2.47236378e-02, -2.34447028e-02,\n",
       "       -4.81328787e-03, -9.30215269e-02, -1.45627614e-02,  6.93487003e-02,\n",
       "       -2.63367556e-02,  1.19335949e-04, -1.84497293e-02,  3.50308180e-01,\n",
       "       -2.28033401e-02, -2.11788695e-02, -3.34771350e-02, -1.08388349e-01,\n",
       "        6.51079044e-02,  1.23856338e-02, -3.23801152e-02, -1.14565063e-02,\n",
       "        1.55162122e-02,  2.82729883e-02, -1.16304643e-01, -1.80899519e-02,\n",
       "        2.70033237e-02, -3.35014425e-02, -3.52596268e-02, -2.60537229e-02,\n",
       "       -2.92745791e-02,  1.88871235e-01, -8.90205521e-03, -1.63584668e-02,\n",
       "        5.64604551e-02,  1.17469672e-02,  1.09735005e-01,  2.69780070e-01,\n",
       "       -2.58220471e-02, -6.17246144e-03, -1.22162355e-02, -2.31605396e-02,\n",
       "       -1.50889941e-02, -1.88155863e-02,  7.91470706e-02, -4.68226969e-02,\n",
       "       -3.24644819e-02, -2.15983782e-02, -1.90386064e-02,  1.53730676e-01,\n",
       "       -3.62092368e-02, -2.63097063e-02, -1.32627971e-02, -3.55459332e-01,\n",
       "       -1.29174134e-02,  1.15387119e-01,  2.20599957e-03,  3.68115902e-01,\n",
       "       -1.65408924e-02,  2.95963231e-03,  5.07506952e-02,  1.03524543e-01,\n",
       "       -1.59884207e-02,  1.68270424e-01, -2.99854241e-02, -2.67411992e-02,\n",
       "       -2.52044164e-02,  9.57952365e-02,  2.41811961e-01, -2.48795636e-02,\n",
       "        8.69974419e-02,  1.62929475e-01,  1.20427541e-01, -1.81378964e-02,\n",
       "       -3.84954299e-04, -3.18620494e-03, -2.12811545e-01,  4.72863810e-03,\n",
       "        6.25636354e-02, -1.60757378e-02,  4.84105438e-01, -3.36890444e-02,\n",
       "       -3.08686644e-02,  9.82982805e-04, -6.70077000e-03, -1.14601357e-02,\n",
       "       -1.07097840e-02, -5.39568486e-04,  1.70380995e-01,  1.23573169e-01,\n",
       "       -3.01517006e-02, -2.39056465e-03, -4.67409268e-02, -1.97247006e-02,\n",
       "       -9.10508446e-03, -1.29282493e-02, -5.41485660e-02, -1.43263057e-01,\n",
       "        2.01964751e-02, -2.68982574e-02,  3.86453718e-02,  1.32092595e-01,\n",
       "        2.27881730e-01, -1.42040495e-02,  7.84474239e-02,  8.37849081e-02,\n",
       "        1.31023042e-02,  1.74260169e-01,  1.81481928e-01,  2.08446443e-01,\n",
       "        2.90558189e-01, -1.60731450e-02, -3.93159613e-02,  1.30426022e-03],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_2/dense_5/kernel:0' shape=(256, 10) dtype=float32, numpy=\n",
       "array([[ 0.05432512,  0.01498794,  0.09378192, ..., -0.1876249 ,\n",
       "        -0.07095113, -0.17087524],\n",
       "       [ 0.00190415, -0.01344071, -0.13024068, ...,  0.19746   ,\n",
       "        -0.13357083, -0.10201047],\n",
       "       [-0.13553594, -0.04623799, -0.05481066, ...,  0.00581059,\n",
       "         0.09365296,  0.02398786],\n",
       "       ...,\n",
       "       [ 0.10229769,  0.0826378 ,  0.19589181, ..., -0.07738955,\n",
       "         0.00498028,  0.08767297],\n",
       "       [-0.24684298, -0.13207583, -0.12355854, ...,  0.4500315 ,\n",
       "         0.15153515,  0.30499202],\n",
       "       [-0.00356028,  0.20399103, -0.07866155, ...,  0.10010336,\n",
       "        -0.03496625, -0.10190053]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_2/dense_5/bias:0' shape=(10,) dtype=float32, numpy=\n",
       "array([ 0.19531798, -0.687023  ,  0.59054476,  0.36306056, -0.17690893,\n",
       "        0.22684103,  0.95620215, -0.20429975, -0.1283199 , -1.135409  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "问题：搞清楚单层全连接神经网络的权重系数有多少，矩阵结构是怎样的。\n",
    "  比如：同一层里的多个神经元，bias有多少个，每个神经元都不同还是共享的？明显是不共享的。\n",
    "  \n",
    "为什么输出的weights要么只有bias，要么只有系数？ 不是应该两者同时都有吗？\n",
    "  \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
