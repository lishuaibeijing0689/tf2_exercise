{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n神经网络的定义方式，获取参数，保存参数\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "神经网络的定义方式，获取参数，保存参数\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run read_fashion_image.ipynb\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([x.reshape(28,28) for x in x_train ])\n",
    "x_test = np.array([x.reshape(28,28) for x in x_test ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方式1：一次性定义全部网络结构\n",
    "model = tf.keras.models.Sequential([\n",
    "                                    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                                    tf.keras.layers.Dense(256, activation='relu',),\n",
    "                                    tf.keras.layers.Dense(10, activation='softmax')\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方式2：以序列方式定义，分别定义每一层\n",
    "def MLP():\n",
    "    flatten_layer = tf.keras.layers.Flatten()\n",
    "    def dense_layer(name):\n",
    "        return tf.keras.layers.Dense(256, activation=tf.nn.relu, name=name)\n",
    "    dropout_layer = tf.keras.layers.Dropout(0.5)\n",
    "    output_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(flatten_layer)\n",
    "    for i in range(2):\n",
    "        model.add(dense_layer(\"dense%d\" % i)) # 每一层起不同的名字\n",
    "        model.add(dropout_layer)\n",
    "    model.add(output_layer)\n",
    "    return model\n",
    "    \n",
    "model = MLP()\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MLP1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方式3：以类的方式定义，更工程化\n",
    "class MLP1(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten_layer = tf.keras.layers.Flatten()\n",
    "        self.dense_layer = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
    "        self.dropout_layer = tf.keras.layers.Dropout(0.5)\n",
    "        self.output_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.flatten_layer(inputs)\n",
    "        x = self.dense_layer(x)\n",
    "        x = self.dense_layer(x)\n",
    "#         for i in range(2):\n",
    "#             x = self.dense_layer(x)\n",
    "#             if training:\n",
    "#                 x = self.dropout_layer(x, training=training)\n",
    "#         x = self.dense_layer(x)\n",
    "#         x = self.dropout_layer(x)\n",
    "#         x = self.dense_layer(x)\n",
    "#         x = self.dropout_layer(x)\n",
    "        output = self.output_layer(x)     \n",
    "        return output\n",
    "    \n",
    "model = MLP1()\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.5),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MLP1.call of <__main__.MLP1 object at 0xb36548780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MLP1.call of <__main__.MLP1 object at 0xb36548780>>, which Python reported as:\n",
      "    def call(self, inputs, training=False):\n",
      "        x = self.flatten_layer(inputs)\n",
      "        x = self.dense_layer(x)\n",
      "        x = self.dense_layer(x)\n",
      "#         for i in range(2):\n",
      "#             x = self.dense_layer(x)\n",
      "#             if training:\n",
      "#                 x = self.dropout_layer(x, training=training)\n",
      "#         x = self.dense_layer(x)\n",
      "#         x = self.dropout_layer(x)\n",
      "#         x = self.dense_layer(x)\n",
      "#         x = self.dropout_layer(x)\n",
      "        output = self.output_layer(x)     \n",
      "        return output\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MLP1.call of <__main__.MLP1 object at 0xb36548780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MLP1.call of <__main__.MLP1 object at 0xb36548780>>, which Python reported as:\n",
      "    def call(self, inputs, training=False):\n",
      "        x = self.flatten_layer(inputs)\n",
      "        x = self.dense_layer(x)\n",
      "        x = self.dense_layer(x)\n",
      "#         for i in range(2):\n",
      "#             x = self.dense_layer(x)\n",
      "#             if training:\n",
      "#                 x = self.dropout_layer(x, training=training)\n",
      "#         x = self.dense_layer(x)\n",
      "#         x = self.dropout_layer(x)\n",
      "#         x = self.dense_layer(x)\n",
      "#         x = self.dropout_layer(x)\n",
      "        output = self.output_layer(x)     \n",
      "        return output\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-66-6bfd99501c30>:14 call\n        x = self.dense_layer(x)\n    /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:812 __call__\n        self.name)\n    /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/input_spec.py:213 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_33 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [None, 256]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-79786c985ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m           )\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2620\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2622\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2623\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2707\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2709\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2710\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    841\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-66-6bfd99501c30>:14 call\n        x = self.dense_layer(x)\n    /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:812 __call__\n        self.name)\n    /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/input_spec.py:213 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_33 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [None, 256]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=5,\n",
    "          batch_size=256\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MLP1.call of <__main__.MLP1 object at 0xb361cf358>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MLP1.call of <__main__.MLP1 object at 0xb361cf358>>, which Python reported as:\n",
      "    def call(self, inputs, training=False):\n",
      "        x = self.flatten_layer(inputs)\n",
      "        x = self.dense_layer(x)\n",
      "        x = self.dense_layer(x)\n",
      "#         for i in range(2):\n",
      "#             x = self.dense_layer(x)\n",
      "#             if training:\n",
      "#                 x = self.dropout_layer(x, training=training)\n",
      "#         x = self.dense_layer(x)\n",
      "#         x = self.dropout_layer(x)\n",
      "#         x = self.dense_layer(x)\n",
      "#         x = self.dropout_layer(x)\n",
      "        output = self.output_layer(x)     \n",
      "        return output\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MLP1.call of <__main__.MLP1 object at 0xb361cf358>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MLP1.call of <__main__.MLP1 object at 0xb361cf358>>, which Python reported as:\n",
      "    def call(self, inputs, training=False):\n",
      "        x = self.flatten_layer(inputs)\n",
      "        x = self.dense_layer(x)\n",
      "        x = self.dense_layer(x)\n",
      "#         for i in range(2):\n",
      "#             x = self.dense_layer(x)\n",
      "#             if training:\n",
      "#                 x = self.dropout_layer(x, training=training)\n",
      "#         x = self.dense_layer(x)\n",
      "#         x = self.dropout_layer(x)\n",
      "#         x = self.dense_layer(x)\n",
      "#         x = self.dropout_layer(x)\n",
      "        output = self.output_layer(x)     \n",
      "        return output\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-61-308e44d85a54>:14 call\n        x = self.dense_layer(x)\n    /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:812 __call__\n        self.name)\n    /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/input_spec.py:213 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_31 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [None, 256]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-399ddf1cd2c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           validation_freq=1)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2620\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2622\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2623\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2707\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2709\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2710\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    841\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-61-308e44d85a54>:14 call\n        x = self.dense_layer(x)\n    /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:812 __call__\n        self.name)\n    /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/input_spec.py:213 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_31 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [None, 256]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=5,\n",
    "          batch_size=256,\n",
    "          validation_data=(x_test, y_test),\n",
    "          validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.8518 - accuracy: 0.6862 - val_loss: 0.6812 - val_accuracy: 0.7404\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.5453 - accuracy: 0.7964 - val_loss: 0.5147 - val_accuracy: 0.8201\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.4900 - accuracy: 0.8190 - val_loss: 0.4907 - val_accuracy: 0.8236\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.4499 - accuracy: 0.8349 - val_loss: 0.4865 - val_accuracy: 0.8114\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.4250 - accuracy: 0.8426 - val_loss: 0.4163 - val_accuracy: 0.8405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3463bcc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=5,\n",
    "          batch_size=256,\n",
    "          validation_data=(x_test, y_test),\n",
    "          validation_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取每一层的权重系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_6/dense0/kernel:0' shape=(784, 256) dtype=float32, numpy=\n",
       "array([[ 0.04358891, -0.05935635,  0.04191222, ...,  0.05466488,\n",
       "        -0.00254817,  0.01894611],\n",
       "       [-0.03180718,  0.05504592, -0.06065722, ...,  0.02531308,\n",
       "         0.00610358, -0.01886529],\n",
       "       [ 0.06975316, -0.06416669, -0.0189217 , ..., -0.06338106,\n",
       "         0.07242534,  0.02792194],\n",
       "       ...,\n",
       "       [-0.01122555,  0.03993281, -0.04979655, ..., -0.02200262,\n",
       "         0.01217559,  0.03844057],\n",
       "       [-0.06139922,  0.0655123 , -0.01436131, ..., -0.05383282,\n",
       "         0.06556807,  0.05354907],\n",
       "       [-0.03813687,  0.03930613,  0.01196447, ..., -0.01439606,\n",
       "         0.06761973, -0.06534402]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_6/dense0/bias:0' shape=(256,) dtype=float32, numpy=\n",
       "array([-1.64143089e-02, -3.06452531e-02,  2.10800245e-02,  7.25917285e-03,\n",
       "       -6.10000174e-03,  5.91970161e-02,  5.28772846e-02,  5.55351824e-02,\n",
       "        1.29053593e-01, -4.09180447e-02,  1.22091519e-02,  1.07123189e-01,\n",
       "        8.99421144e-03,  2.33754218e-01, -4.43066396e-02, -1.44509338e-02,\n",
       "       -2.71365047e-02,  1.11449905e-01, -1.79233830e-02, -1.60933226e-01,\n",
       "        1.51089476e-02,  2.29997918e-01,  1.90238431e-02, -2.29381560e-03,\n",
       "        9.67024118e-02, -6.61122100e-03,  4.08737622e-02, -2.50958055e-02,\n",
       "       -2.32944284e-02,  1.43720778e-02,  9.16180387e-03,  2.50004735e-02,\n",
       "        1.33906044e-02,  5.90289757e-02, -1.51758492e-01, -2.25578761e-03,\n",
       "       -1.30756885e-01, -2.02967715e-03,  5.73362559e-02,  1.08117436e-03,\n",
       "       -6.08546368e-04, -4.22387309e-02,  1.43802568e-01,  1.03909791e-01,\n",
       "        1.70647532e-01,  3.40869606e-01, -7.56302103e-02,  1.29021600e-01,\n",
       "        1.29899561e-01, -1.57940481e-02,  7.10265990e-03, -2.05052644e-02,\n",
       "       -5.54233883e-03, -7.02755451e-02,  1.67470910e-02,  3.89567986e-02,\n",
       "       -1.11092813e-01,  3.53745341e-01, -1.34623144e-02,  3.66894621e-03,\n",
       "       -7.00788107e-03, -6.81467773e-03, -1.22392271e-02, -1.37264421e-03,\n",
       "        1.24335557e-01, -2.19971631e-02, -3.14872265e-02, -3.27765822e-01,\n",
       "        1.95607692e-02, -3.91850621e-02, -1.95575450e-02,  5.08191064e-04,\n",
       "       -3.72983026e-03,  5.56451529e-02,  5.95086105e-02,  1.07781664e-01,\n",
       "        1.15316540e-01,  6.37958720e-02,  1.29398694e-02, -2.20194813e-02,\n",
       "       -2.94307303e-02, -2.27301009e-02, -1.96889695e-02,  2.25068126e-02,\n",
       "        4.01542634e-02,  1.57166183e-01, -3.33875045e-02,  2.08213791e-01,\n",
       "        1.09995149e-01,  6.67611253e-04, -7.53154140e-03,  1.73793007e-02,\n",
       "       -1.00809895e-01,  2.13865973e-02,  1.03649683e-02,  2.82415926e-01,\n",
       "       -2.16322225e-02,  2.13617936e-01, -3.62701453e-02,  3.65153104e-02,\n",
       "        1.68748274e-01, -7.84180686e-03, -9.69336554e-03,  3.51984888e-01,\n",
       "       -4.19047289e-03,  1.66669771e-01, -1.62591681e-01,  1.40640035e-01,\n",
       "        1.32393492e-02, -1.87425371e-02,  1.26851127e-01, -4.41895463e-02,\n",
       "       -1.59235131e-02,  1.57584593e-01, -1.06436135e-02,  5.24657965e-03,\n",
       "       -1.14500888e-01,  6.65089814e-03,  4.21515293e-02,  2.11640358e-01,\n",
       "        6.33334625e-04,  1.69869840e-01,  8.73886049e-02, -5.17206267e-03,\n",
       "       -1.63407773e-02, -1.32838544e-02,  4.74359561e-03,  1.76846996e-01,\n",
       "        2.65128072e-02, -9.03347135e-03, -1.47915734e-02, -2.35098898e-02,\n",
       "       -3.18538487e-01,  1.35420993e-01,  1.95260569e-01,  1.69748012e-02,\n",
       "       -1.14144534e-02,  2.85688937e-01,  2.84422264e-02, -1.36111211e-02,\n",
       "        1.18341288e-02, -3.16935293e-02, -3.25544663e-02, -6.99030235e-03,\n",
       "       -2.27992218e-02, -2.59774774e-02, -1.79878063e-02,  1.20205237e-02,\n",
       "        1.76834583e-01,  4.95639481e-02,  6.99102730e-02,  1.80124909e-01,\n",
       "        3.86502072e-02,  5.19315526e-03, -2.28052447e-03, -3.42411809e-02,\n",
       "        2.84213759e-02, -3.17622833e-02, -2.65237801e-02, -1.19487960e-02,\n",
       "       -1.79477129e-02, -2.30578646e-01, -1.71701182e-02, -7.51253450e-04,\n",
       "       -2.81854928e-03,  8.07053819e-02,  5.78380749e-02,  1.54709965e-01,\n",
       "        2.85112947e-01, -2.00556591e-02,  4.36338186e-02,  3.50648612e-02,\n",
       "        3.75434786e-01,  6.32305890e-02, -7.50608668e-02,  9.71078873e-03,\n",
       "        1.36820391e-01,  5.18761277e-02,  2.12562159e-01, -3.00908163e-02,\n",
       "       -2.27173436e-02, -2.98987236e-02,  5.24334237e-02,  1.54275149e-01,\n",
       "       -9.72012349e-05,  4.73519787e-02, -7.22734183e-02,  2.01422293e-02,\n",
       "        2.08916962e-02,  9.05746743e-02,  1.90682756e-03,  1.05255030e-01,\n",
       "       -2.54862942e-02, -1.46923028e-02,  1.70095921e-01,  6.46070763e-02,\n",
       "       -7.98362121e-03, -1.33800786e-04, -1.12061407e-02, -2.32690964e-02,\n",
       "        1.75464749e-01,  1.97031908e-03,  1.24558307e-01,  1.23890735e-01,\n",
       "       -5.25006792e-03,  1.21207368e-02, -1.87964402e-02,  3.70738320e-02,\n",
       "        3.77717540e-02,  3.98735292e-02,  3.36701423e-02, -3.25630531e-02,\n",
       "       -4.54194024e-02,  5.07676244e-01,  3.36035907e-01, -7.50601478e-03,\n",
       "       -1.40147284e-02, -1.17626414e-01, -8.81125871e-03,  7.86392093e-02,\n",
       "        4.95595597e-02,  2.52666444e-01,  1.12740189e-01,  5.01660071e-02,\n",
       "       -2.95889713e-02,  2.54136592e-01, -1.25579117e-02,  1.22237310e-01,\n",
       "        1.45596564e-01,  1.89268917e-01,  4.88713235e-02, -2.14050803e-02,\n",
       "        1.49006024e-01,  1.11743823e-01, -1.74205974e-02, -2.62671541e-02,\n",
       "       -3.48547213e-02,  1.33812368e-01, -2.13803500e-02,  2.11819097e-01,\n",
       "       -2.56690034e-03, -7.06755091e-03,  1.18732393e-01, -2.58782860e-02,\n",
       "        2.47699618e-02, -1.49728712e-02,  2.06608951e-01,  3.62021178e-02,\n",
       "        1.01992697e-01,  4.91217524e-02,  1.20695382e-02, -1.46902263e-01,\n",
       "       -1.83348190e-02, -8.42361990e-03, -9.92779341e-03,  1.60930045e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_6/dense1/kernel:0' shape=(256, 256) dtype=float32, numpy=\n",
       "array([[-0.02766217,  0.03732958, -0.08450466, ...,  0.01432702,\n",
       "        -0.07911391,  0.02257321],\n",
       "       [-0.06539106, -0.10576568,  0.0250215 , ..., -0.06986461,\n",
       "        -0.08995315,  0.02492773],\n",
       "       [ 0.07400792, -0.10849069,  0.05458679, ..., -0.09829598,\n",
       "        -0.0128841 , -0.00713505],\n",
       "       ...,\n",
       "       [-0.09862264, -0.06201045, -0.04176588, ..., -0.06321128,\n",
       "        -0.07110613, -0.0048173 ],\n",
       "       [-0.01109714, -0.07586544, -0.09420383, ...,  0.10271026,\n",
       "         0.0373575 , -0.03779222],\n",
       "       [ 0.06439859, -0.00620481,  0.07330702, ...,  0.09659082,\n",
       "         0.0408005 , -0.07447951]], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_6/dense1/bias:0' shape=(256,) dtype=float32, numpy=\n",
       "array([-3.42499204e-02,  1.27566978e-01,  1.13002099e-01, -4.76772450e-02,\n",
       "        1.30573869e-01, -2.25142110e-02,  1.13083623e-01,  9.32680592e-02,\n",
       "        2.66100783e-02,  1.87443882e-01,  4.39047907e-03,  1.71451285e-01,\n",
       "        1.34939030e-01, -2.09078826e-02, -1.66190118e-02, -1.14746112e-02,\n",
       "        1.28116786e-01,  4.21935767e-02,  4.36974056e-02,  5.52491993e-02,\n",
       "        9.27499682e-02,  1.60301160e-02,  2.26601154e-01,  1.59883033e-02,\n",
       "       -3.56972590e-02,  9.48188733e-03,  2.37283245e-01, -4.87253107e-02,\n",
       "       -2.16226876e-02, -4.65673022e-02, -4.51437980e-02,  1.61715329e-01,\n",
       "        3.78791317e-02, -4.60289083e-02,  1.13930240e-01,  8.81216004e-02,\n",
       "        1.02559887e-01,  3.13949548e-02, -3.05244327e-02, -4.55821166e-04,\n",
       "        3.80917005e-02,  3.70457470e-02,  6.57953415e-03, -1.27722770e-02,\n",
       "        1.90458938e-01,  9.79682580e-02,  4.37377095e-02,  1.54334769e-01,\n",
       "        1.48185149e-01,  1.13342293e-01,  1.15064539e-01, -1.25660207e-02,\n",
       "       -3.10764089e-02,  2.68275850e-02, -2.06056628e-02,  4.71345894e-02,\n",
       "       -2.74674427e-02,  4.13729101e-02,  1.27104387e-01, -2.05853004e-02,\n",
       "       -2.90514976e-02, -1.80713516e-02,  3.60872671e-02,  1.43453732e-01,\n",
       "        3.92891876e-02,  2.91679669e-02,  3.45390476e-02,  5.59598394e-02,\n",
       "       -6.12953957e-03,  3.18193078e-01,  1.50055811e-01,  1.19290687e-01,\n",
       "       -3.39976884e-02,  2.52475217e-02,  8.01669508e-02, -2.66954768e-02,\n",
       "        4.19274457e-02, -2.46808790e-02,  5.30719012e-03, -1.84749607e-02,\n",
       "        2.41555553e-02, -1.27690071e-02,  8.72928649e-02, -7.47058690e-02,\n",
       "       -1.09034926e-01,  4.67444919e-02,  1.34374931e-01,  2.87399024e-01,\n",
       "        4.26555891e-03,  2.22202376e-01,  9.17559210e-03,  6.03269972e-02,\n",
       "        1.12710804e-01,  8.14314112e-02,  6.23957366e-02,  2.05951720e-01,\n",
       "       -4.70379554e-02, -2.05597915e-02, -6.08441792e-02, -2.78365705e-02,\n",
       "        8.33555609e-02, -6.21803943e-03,  2.60801584e-01,  4.40651402e-02,\n",
       "       -3.73511482e-03, -1.75628886e-02,  2.30230093e-02,  2.84418911e-02,\n",
       "        7.43499324e-02, -3.56908925e-02, -8.37440342e-02,  9.17928293e-02,\n",
       "        2.99106389e-02,  1.03943758e-01,  3.76491286e-02,  9.37914997e-02,\n",
       "        1.84260309e-04, -2.36626398e-02,  7.62478709e-02,  9.29892734e-02,\n",
       "        1.04130823e-02,  7.76096061e-02, -2.82237064e-02,  1.92302555e-01,\n",
       "        3.68785948e-01,  6.78133816e-02, -1.97657328e-02, -2.49312702e-03,\n",
       "        1.65059850e-01, -1.02733709e-02,  9.57605150e-03, -7.62685388e-03,\n",
       "       -2.73583028e-02,  7.05295801e-02, -6.67978963e-03,  5.84453531e-02,\n",
       "        4.60857973e-02, -2.75617721e-03,  1.34618402e-01, -2.48744916e-02,\n",
       "       -5.85183613e-02, -2.35236567e-02,  2.31224597e-01,  1.53212436e-02,\n",
       "        2.34476523e-03, -2.84946989e-02,  5.76899908e-02, -3.38754952e-02,\n",
       "        7.98405036e-02,  6.21806756e-02,  3.00399531e-02,  5.32440320e-02,\n",
       "        3.48017588e-02,  1.33396447e-01, -3.09984256e-02,  2.68814594e-01,\n",
       "        1.07854031e-01,  1.44819796e-01, -4.08782214e-02,  5.35865463e-02,\n",
       "       -5.47640473e-02,  8.98804367e-02,  1.66925922e-01,  1.85286313e-01,\n",
       "       -5.89077137e-02,  1.39260232e-01,  1.37427286e-03,  1.09848613e-03,\n",
       "        2.00676243e-03, -8.07766244e-02,  2.00708956e-01,  1.09769881e-01,\n",
       "       -8.39039683e-02, -2.19947901e-02, -7.03264698e-02,  9.83454734e-02,\n",
       "       -1.02677364e-02, -5.66722676e-02, -3.80775072e-02,  1.14277855e-01,\n",
       "        4.05097865e-02,  5.95472939e-02,  1.22713462e-01, -1.23125762e-02,\n",
       "        6.10145181e-02,  5.08348458e-02,  4.14298475e-02, -5.45652397e-02,\n",
       "       -3.53868789e-04,  1.25502301e-02, -1.67080890e-02,  1.56736001e-01,\n",
       "       -5.72113656e-02,  2.85979301e-01, -1.17828492e-02, -2.16059703e-02,\n",
       "       -2.74306796e-02, -3.77476402e-02, -1.92728881e-02,  8.79980326e-02,\n",
       "        2.77242493e-02, -3.05327922e-02, -3.26699466e-02, -3.45091112e-02,\n",
       "        3.22746426e-01,  9.88412276e-02, -2.55908463e-02, -2.20120270e-02,\n",
       "       -3.65409963e-02,  1.59272086e-02, -1.59754641e-02, -1.13065308e-02,\n",
       "        1.85671505e-02,  1.33676887e-01,  1.41864926e-01,  1.00945204e-01,\n",
       "        1.38065159e-01,  9.32201147e-02,  2.56839246e-01,  1.86606683e-02,\n",
       "       -8.83944333e-02,  5.85831329e-02, -3.22713591e-02,  5.17515726e-02,\n",
       "        4.83951941e-02,  1.71950758e-01,  1.09909065e-01,  4.64096069e-02,\n",
       "        3.79408002e-02,  2.99958438e-02,  2.39938602e-01,  7.37439608e-03,\n",
       "       -3.62305120e-02,  4.38997597e-02, -5.35452701e-02, -1.24358246e-02,\n",
       "       -1.75227560e-02,  1.66248038e-01, -1.28105246e-02,  9.26464610e-03,\n",
       "        4.82030548e-02, -1.88707244e-02, -1.14965692e-01, -6.93808571e-02,\n",
       "       -2.41193306e-02, -1.19870221e-02, -6.15065470e-02,  1.47598818e-01,\n",
       "        1.21255852e-01,  1.11279488e-01, -4.02979925e-03,  1.44653767e-01,\n",
       "       -1.12339389e-02,  3.44033539e-02, -3.28442752e-02,  1.58190608e-01],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_6/dense_14/kernel:0' shape=(256, 10) dtype=float32, numpy=\n",
       "array([[-0.11226083, -0.0979874 , -0.03733522, ...,  0.2446965 ,\n",
       "        -0.12963848,  0.26193267],\n",
       "       [ 0.15002106, -0.10534374, -0.06269068, ..., -0.1178015 ,\n",
       "        -0.18511565, -0.08772626],\n",
       "       [ 0.154404  ,  0.0402348 , -0.1594996 , ...,  0.06548733,\n",
       "        -0.07345035, -0.12319739],\n",
       "       ...,\n",
       "       [-0.12877622, -0.06618959, -0.23317517, ...,  0.46487254,\n",
       "         0.01301841,  0.36370137],\n",
       "       [ 0.0692012 ,  0.02984063, -0.09269484, ..., -0.04543467,\n",
       "        -0.07462528,  0.00701786],\n",
       "       [-0.01948133, -0.12905468,  0.37550774, ..., -0.00858693,\n",
       "        -0.10251138, -0.17401764]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_6/dense_14/bias:0' shape=(10,) dtype=float32, numpy=\n",
       "array([ 0.05210388, -0.42345208,  0.55860037,  0.24357876, -0.2022633 ,\n",
       "        0.10888381,  0.62025636, -0.08870672, -0.06511167, -0.80388385],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "问题：搞清楚单层全连接神经网络的权重系数有多少，矩阵结构是怎样的。\n",
    "  比如：同一层里的多个神经元，bias有多少个，每个神经元都不同还是共享的？明显是不共享的。\n",
    "  \n",
    "为什么输出的weights要么只有bias，要么只有系数？ 不是应该两者同时都有吗？\n",
    "答：要给每个layer设置name参数，这样weights就不会被覆盖写，否则，相同name的weights只会记录一份。\n",
    "\n",
    "  \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
